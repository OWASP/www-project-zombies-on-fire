"""
LLM integration service for AI-powered content generation.
"""

from abc import ABC, abstractmethod
from typing import Optional
import asyncio

from app.config import settings


class BaseLLMProvider(ABC):
    """Base class for LLM providers."""

    @abstractmethod
    async def generate(self, prompt: str, max_tokens: int = 4000) -> str:
        """Generate content from a prompt."""
        pass


class OpenAIProvider(BaseLLMProvider):
    """OpenAI GPT provider."""

    def __init__(self):
        try:
            from openai import AsyncOpenAI
            self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
            self.model = settings.LLM_MODEL
        except ImportError:
            raise ImportError("openai package not installed. Run: pip install openai")

    async def generate(self, prompt: str, max_tokens: int = 4000) -> str:
        """Generate content using OpenAI."""
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert in creating tabletop exercise materials. Provide detailed, well-structured content in markdown format."
                },
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=0.7,
        )
        return response.choices[0].message.content


class AnthropicProvider(BaseLLMProvider):
    """Anthropic Claude provider."""

    def __init__(self):
        try:
            from anthropic import AsyncAnthropic
            self.client = AsyncAnthropic(api_key=settings.ANTHROPIC_API_KEY)
            self.model = settings.LLM_MODEL if "claude" in settings.LLM_MODEL else "claude-3-sonnet-20240229"
        except ImportError:
            raise ImportError("anthropic package not installed. Run: pip install anthropic")

    async def generate(self, prompt: str, max_tokens: int = 4000) -> str:
        """Generate content using Anthropic Claude."""
        message = await self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            messages=[
                {"role": "user", "content": prompt}
            ],
            system="You are an expert in creating tabletop exercise materials. Provide detailed, well-structured content in markdown format."
        )
        return message.content[0].text


class MockProvider(BaseLLMProvider):
    """Mock provider for testing without API calls."""

    async def generate(self, prompt: str, max_tokens: int = 4000) -> str:
        """Generate mock content for testing."""
        await asyncio.sleep(0.1)  # Simulate API latency

        # Extract context from prompt to generate relevant mock content
        if "description" in prompt.lower():
            return "This document provides comprehensive guidance for the tabletop exercise, covering key scenarios, decision points, and learning objectives designed to challenge and develop participants' critical thinking skills."

        if "learning goals" in prompt.lower() or "learning objectives" in prompt.lower():
            return """1. Understand the key decision-making frameworks applicable to crisis situations
2. Develop skills in rapid information assessment and prioritization
3. Practice collaborative problem-solving under pressure
4. Learn to communicate effectively during high-stress scenarios
5. Identify personal and team strengths and areas for improvement
6. Apply lessons learned to real-world operational contexts"""

        # Default content generation
        return f"""# Generated Content

## Overview
This section provides the main content for the requested document type.

## Key Points
- Point 1: Critical considerations for the exercise
- Point 2: Important factors to address
- Point 3: Decision points and challenges

## Detailed Content
Lorem ipsum content would be generated here based on the specific tabletop
exercise parameters. In production, this would be replaced with AI-generated
content specific to the scenario.

## Summary
This document supports the effective execution of the tabletop exercise
by providing structured guidance and reference materials.

---
*Generated by Zombies on Fire Tabletop Portal*
"""


class LLMService:
    """
    Main LLM service that abstracts provider-specific implementations.

    Supports multiple providers: OpenAI, Anthropic, and Mock (for testing).
    """

    def __init__(self, provider: Optional[str] = None):
        provider = provider or settings.LLM_PROVIDER

        if provider == "openai":
            self._provider = OpenAIProvider()
        elif provider == "anthropic":
            self._provider = AnthropicProvider()
        elif provider == "mock":
            self._provider = MockProvider()
        else:
            raise ValueError(f"Unknown LLM provider: {provider}")

        self.provider_name = provider

    async def generate(self, prompt: str, max_tokens: int = 4000) -> str:
        """
        Generate content from a prompt.

        Args:
            prompt: The prompt to send to the LLM
            max_tokens: Maximum tokens in the response

        Returns:
            Generated content as a string
        """
        return await self._provider.generate(prompt, max_tokens)


def get_llm_service() -> LLMService:
    """Get the configured LLM service instance."""
    return LLMService()
